{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "_04krHmOdtLo"
      ],
      "mount_file_id": "1uOeWsVX4rPH6nrOyFkhCBYoXNKAaXlL_",
      "authorship_tag": "ABX9TyMDr+FGgtD0JdXJMMWUhFiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bok-h22/TIL-202303/blob/master/%EC%B5%9C%EC%A2%85_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8%EB%A7%81_%EC%A7%80%EC%9C%A4__%ED%9D%AC%EC%A4%80_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기본 세팅"
      ],
      "metadata": {
        "id": "Xuqkc993d7yn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcZSEfy_a2Ni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f465c38-1c29-4636-f6e0-fc307f8cc831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/7.8 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/7.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/7.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m7.3/7.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.3\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting focal_loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.10/dist-packages (from focal_loss) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal_loss) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2->focal_loss) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal_loss) (3.2.2)\n",
            "Installing collected packages: focal_loss\n",
            "Successfully installed focal_loss-0.0.7\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers\n",
        "!pip install sentencepiece\n",
        "!pip install focal_loss\n",
        "!pip install scikit-learn --upgrade -user\n",
        "!pip install keras --upgrade -user\n",
        "!pip install tensorflow --upgrade -user\n",
        "!pip install pickle --upgrade -user"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "-PY7V8tWa9c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "3lLHnc07bTij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 기업 리뷰 데이터"
      ],
      "metadata": {
        "id": "6GawKjRjbbOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input/txt\n",
        "txt_raw = pd.read_csv('/content/drive/MyDrive/한스펠 돌린 최종본.csv', encoding = 'utf-8')\n",
        "\n",
        "txt_raw= txt_raw.drop(txt_raw[txt_raw['cleand_up'].isna() == True].index)\n",
        "txt_raw= txt_raw.drop(txt_raw[txt_raw['cleand_down'].isna() == True].index)\n",
        "#data['label'] = data['label'].astype('str')\n",
        "\n",
        "txt_raw = txt_raw[['corp', 'stock_code', 'year', 'rank', 'label', 'cleand_up', 'cleand_down']]"
      ],
      "metadata": {
        "id": "ckrUIUrRbR56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 재무데이터 (Model A)"
      ],
      "metadata": {
        "id": "vuVZU4Kwbeg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input/finacial data\n",
        "finalcial_raw = pd.read_csv('/content/drive/MyDrive/final_a_df.csv', encoding = 'cp949')\n",
        "\n",
        "finalcial_raw = finalcial_raw[['corp', 'stock_code', 'year', 'rank',\n",
        "       'ebitda_margin', 'ebitda_to_interest_expense', 'debt_ratio',\n",
        "       'dependence_on_net_borrowings', 'net_borrowings_to_ebitda', 'revenue',\n",
        "       'cogs', 'selling_general_administrative_expenses', 'ebit',\n",
        "       'ebit_margin', 'ebitda_to_sales_revenue', 'total_assets',\n",
        "       'return_on_assets', 'ebitda', 'financial_expenses', 'corporate_tax',\n",
        "       'operating_cash_flow', 'free_cash_flow', 'total_liabilities',\n",
        "       'total_equity', 'total_borrowings', 'net_borrowings',\n",
        "       'borrowing_dependency', 'total_borrowings_to_ebitda',\n",
        "       'debt_to_net_income_ratio', 'total_assets_leverage',\n",
        "       'current_liabilities', 'working_capital', 'current_liabilities_ratio',\n",
        "       'quick_assets', 'quick_ratio', 'cash_and_cash_equivalents',\n",
        "       'short_term_borrowings', 'days_sales_outstanding',\n",
        "       'market_capitalization', 'minimum_wage', 'us_kor_exchange_avg',\n",
        "       'ppi_year', 'kor_usa_ir_diff', 'kr_standard_yield', 'count', 'rating',\n",
        "       'paywellfare', 'worklifebal', 'culture', 'opportunity', 'manager',\n",
        "       'recommend', 'ceo', 'potential', 'crb_index_avg']]\n",
        "\n",
        "finalcial_raw = finalcial_raw[finalcial_raw['rank'].isna() == False]"
      ],
      "metadata": {
        "id": "8qEkGYHGbibG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge\n",
        "total_raw = txt_raw.merge(finalcial_raw, on = ['corp', 'stock_code', 'year', 'rank'], how = 'inner')\n",
        "len(total_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SMILTi2cHGk",
        "outputId": "94264f19-bd13-465f-83db-f0fb40436f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30463"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분할"
      ],
      "metadata": {
        "id": "_04krHmOdtLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test = train_test_split(total_raw, test_size=0.25, stratify=total_raw['label'].to_list())\n",
        "data_train, data_valid = train_test_split(data_train, test_size=0.2, stratify=data_train['label'].to_list())"
      ],
      "metadata": {
        "id": "9RKcJvgkdsBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "f-7Tbl9ve8Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 텍스트 데이터"
      ],
      "metadata": {
        "id": "d_VHDqKXfA-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 작성\n",
        "with open('test_review.txt', 'a', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(data_train['cleand_up']))\n",
        "    f.write('\\n'.join(data_train['cleand_down']))\n",
        "    f.write('\\n'.join(data_test['cleand_up']))\n",
        "    f.write('\\n'.join(data_test['cleand_down']))"
      ],
      "metadata": {
        "id": "M5zxRK4hfelO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이즈\n",
        "from tokenizers import SentencePieceBPETokenizer\n",
        "\n",
        "tokenizer = SentencePieceBPETokenizer()\n",
        "tokenizer.train('test_review.txt', vocab_size=5000, min_frequency=3)\n",
        "\n",
        "# train\n",
        "data_train['sp_up_train'] = data_train['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "data_train['sp_down_train'] = data_train['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "\n",
        "#valid\n",
        "data_valid['sp_up_valid'] = data_valid['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "data_valid['sp_down_valid'] = data_valid['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "\n",
        "# test\n",
        "data_test['sp_up_test'] = data_test['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "data_test['sp_down_test'] = data_test['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "\n",
        "# output\n",
        "tokenized_up_train = data_train['sp_up_train']\n",
        "tokenized_up_valid = data_valid['sp_up_valid']\n",
        "tokenized_up_test = data_test['sp_up_test']\n",
        "\n",
        "tokenized_down_train = data_train['sp_down_train']\n",
        "tokenized_down_valid = data_valid['sp_down_valid']\n",
        "tokenized_down_test = data_test['sp_down_test']"
      ],
      "metadata": {
        "id": "9wxU6_bUfJk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩\n",
        "max_length = 50\n",
        "\n",
        "# train\n",
        "sequences_up_train = pad_sequences(tokenized_up_train, maxlen=max_length, padding='post', truncating='post')\n",
        "sequences_down_train = pad_sequences(tokenized_up_train, maxlen=max_length, padding='post', truncating='post')\n",
        "labels_train = np.array(data_train['label'])\n",
        "\n",
        "# valid\n",
        "sequences_up_valid = pad_sequences(tokenized_up_valid, maxlen=max_length, padding='post', truncating='post')\n",
        "sequences_down_valid = pad_sequences(tokenized_up_valid, maxlen=max_length, padding='post', truncating='post')\n",
        "labels_valid = np.array(data_valid['label'])\n",
        "\n",
        "# test\n",
        "sequences_up_test = pad_sequences(tokenized_up_test, maxlen=max_length, padding='post', truncating='post')\n",
        "sequences_down_test = pad_sequences(tokenized_up_test, maxlen=max_length, padding='post', truncating='post')\n",
        "labels_test = np.array(data_test['label'])"
      ],
      "metadata": {
        "id": "B-iv93bRgYyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(labels_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz9HTuRyOZSV",
        "outputId": "86cb2281-2d74-40b6-d352-40f6fbceaeff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 재무데이터"
      ],
      "metadata": {
        "id": "IDEmMt6AiSuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 표준화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "columns = ['ebitda_margin', 'ebitda_to_interest_expense',\n",
        "       'debt_ratio', 'dependence_on_net_borrowings',\n",
        "       'net_borrowings_to_ebitda', 'revenue', 'cogs',\n",
        "       'selling_general_administrative_expenses', 'ebit', 'ebit_margin',\n",
        "       'ebitda_to_sales_revenue', 'total_assets', 'return_on_assets', 'ebitda',\n",
        "       'financial_expenses', 'corporate_tax', 'operating_cash_flow',\n",
        "       'free_cash_flow', 'total_liabilities', 'total_equity',\n",
        "       'total_borrowings', 'net_borrowings', 'borrowing_dependency',\n",
        "       'total_borrowings_to_ebitda', 'debt_to_net_income_ratio',\n",
        "       'total_assets_leverage', 'current_liabilities', 'working_capital',\n",
        "       'current_liabilities_ratio', 'quick_assets', 'quick_ratio',\n",
        "       'cash_and_cash_equivalents', 'short_term_borrowings',\n",
        "       'days_sales_outstanding',\n",
        "       'market_capitalization', 'minimum_wage', 'us_kor_exchange_avg',\n",
        "       'ppi_year', 'kor_usa_ir_diff', 'kr_standard_yield', 'count', 'rating',\n",
        "       'paywellfare', 'worklifebal', 'culture', 'opportunity', 'manager',\n",
        "       'recommend', 'ceo', 'potential', 'crb_index_avg']\n",
        "\n",
        "print(len(columns))\n",
        "\n",
        "# train\n",
        "scaler.fit(data_train[columns])\n",
        "scaled_data_train = scaler.transform(data_train[columns])\n",
        "\n",
        "# valid\n",
        "scaled_data_valid = scaler.transform(data_valid[columns])\n",
        "\n",
        "# test\n",
        "scaled_data_test = scaler.transform(data_test[columns])\n",
        "\n",
        "# export scaler\n",
        "import pickle\n",
        "\n",
        "with open(\"scaler.pkl\", \"wb\") as file:\n",
        "    pickle.dump(scaler, file)"
      ],
      "metadata": {
        "id": "gNEBH3ZviT5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c5745c-efed-4fc6-dc0e-bc162cdf3d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝"
      ],
      "metadata": {
        "id": "26d0cxVjj1s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 모델 구축"
      ],
      "metadata": {
        "id": "9In8wgv0j58g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import keras\n",
        "\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT_JdsN1Xo1v",
        "outputId": "49fd0490-7fd1-4d56-9eec-e8546d46e591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패키지\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Dropout, BatchNormalization, concatenate\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# GRU(Gated Recurrent Unit)\n",
        "def review_GRU():\n",
        "  input_layer = Input(shape=(max_length,))\n",
        "  embedding_layer = Embedding(input_dim=len(tokenizer.get_vocab()), output_dim=512, input_length=max_length)(input_layer)\n",
        "  gru_1 = GRU(256, activation='tanh', return_sequences=True)(embedding_layer)\n",
        "  gru_2 = GRU(128, activation='tanh')(gru_1)\n",
        "\n",
        "  return input_layer, gru_2\n",
        "\n",
        "# MLP(Multi-Layer Perceptron)\n",
        "def fs_MLP():\n",
        "  input_layer = Input(shape=[51,])\n",
        "  mlp_1 = Dense(32, activation='relu')(input_layer)\n",
        "  return input_layer, mlp_1\n",
        "\n",
        "# 모델 정의\n",
        "input_layer_up, output_up = review_GRU()\n",
        "input_layer_down, output_down = review_GRU()\n",
        "input_layer_fs, output_fs = fs_MLP()\n",
        "\n",
        "# 위, 아래 방향 리뷰 결과와 벡터 결과를 concatenate하여 하나의 벡터로 만듭니다.\n",
        "concat_input = concatenate([output_up, output_down, output_fs], axis=-1)\n",
        "\n",
        "# Dropout과 BatchNormalization을 거쳐 은닉층 구성\n",
        "dropout_1 = Dropout(0.2)(concat_input)\n",
        "batchnorm_1 = BatchNormalization()(dropout_1)\n",
        "dense_1 = Dense(64, activation='relu')(batchnorm_1)\n",
        "\n",
        "dropout_2 = Dropout(0.2)(dense_1)\n",
        "batchnorm_2 = BatchNormalization()(dropout_2)\n",
        "dense_2 = Dense(32, activation='relu')(batchnorm_2)\n",
        "\n",
        "# Output layer: 최종 출력을 위해 Softmax 활성화 함수가 적용된 Dense 레이어를 사용\n",
        "output_layer = Dense(9, activation='softmax')(dense_2)\n",
        "\n",
        "# Create the functional model: 위에서 정의한 입력 레이어와 출력 레이어로 모델 생성\n",
        "model = Model(inputs=[input_layer_up, input_layer_down, input_layer_fs], outputs=output_layer)\n",
        "\n",
        "# Create an optimizer with a custom learning rate\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Focal Loss: SparseCategoricalFocalLoss(gamma=2)를 사용하여 커스텀 Loss 함수 생성\n",
        "loss_func = SparseCategoricalFocalLoss(gamma=2)\n",
        "\n",
        "# Early Stopping 콜백 정의\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Compile the model: 옵티마이저, Loss 함수, 평가 메트릭 설정\n",
        "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n",
        "\n",
        "# 모델 아키텍처 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKafM-j0j3Zj",
        "outputId": "91d489b1-e4bf-4357-c017-c78adfd0862b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 512)      2560000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 50, 512)      2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 50, 256)      591360      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 50, 256)      591360      ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 51)]         0           []                               \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 128)          148224      ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    (None, 128)          148224      ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           1664        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 288)          0           ['gru_1[0][0]',                  \n",
            "                                                                  'gru_3[0][0]',                  \n",
            "                                                                  'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 288)          0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 288)         1152        ['dropout[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           18496       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64)          256         ['dropout_1[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           2080        ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 9)            297         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,623,113\n",
            "Trainable params: 6,622,409\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 학습"
      ],
      "metadata": {
        "id": "irYJDb7fj7rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([sequences_up_train, sequences_down_train, scaled_data_train],\n",
        "                    labels_train,\n",
        "                    validation_data=([sequences_up_valid, sequences_down_valid, scaled_data_valid], labels_valid),\n",
        "                    verbose= 1,\n",
        "                    epochs=100,\n",
        "                    batch_size=64,\n",
        "                    callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4p0akiwo0Qk",
        "outputId": "f71c92ef-e30f-4006-ef03-7a28f444dca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "286/286 [==============================] - 52s 133ms/step - loss: 1.8877 - accuracy: 0.1757 - val_loss: 1.5870 - val_accuracy: 0.1724\n",
            "Epoch 2/100\n",
            "286/286 [==============================] - 14s 48ms/step - loss: 1.6069 - accuracy: 0.2197 - val_loss: 1.4060 - val_accuracy: 0.2963\n",
            "Epoch 3/100\n",
            "286/286 [==============================] - 9s 31ms/step - loss: 1.3453 - accuracy: 0.2981 - val_loss: 1.2412 - val_accuracy: 0.3206\n",
            "Epoch 4/100\n",
            "286/286 [==============================] - 8s 26ms/step - loss: 1.1188 - accuracy: 0.3904 - val_loss: 1.0464 - val_accuracy: 0.5118\n",
            "Epoch 5/100\n",
            "286/286 [==============================] - 9s 33ms/step - loss: 0.9641 - accuracy: 0.4557 - val_loss: 0.8418 - val_accuracy: 0.4919\n",
            "Epoch 6/100\n",
            "286/286 [==============================] - 8s 28ms/step - loss: 0.8523 - accuracy: 0.5029 - val_loss: 0.6616 - val_accuracy: 0.6002\n",
            "Epoch 7/100\n",
            "286/286 [==============================] - 8s 29ms/step - loss: 0.7577 - accuracy: 0.5523 - val_loss: 0.6737 - val_accuracy: 0.6256\n",
            "Epoch 8/100\n",
            "286/286 [==============================] - 8s 27ms/step - loss: 0.6944 - accuracy: 0.5837 - val_loss: 0.5455 - val_accuracy: 0.7081\n",
            "Epoch 9/100\n",
            "286/286 [==============================] - 8s 27ms/step - loss: 0.6407 - accuracy: 0.6022 - val_loss: 0.5116 - val_accuracy: 0.6932\n",
            "Epoch 10/100\n",
            "286/286 [==============================] - 8s 27ms/step - loss: 0.5994 - accuracy: 0.6275 - val_loss: 0.4727 - val_accuracy: 0.7398\n",
            "Epoch 11/100\n",
            "286/286 [==============================] - 7s 25ms/step - loss: 0.5621 - accuracy: 0.6463 - val_loss: 0.4380 - val_accuracy: 0.7718\n",
            "Epoch 12/100\n",
            "286/286 [==============================] - 7s 26ms/step - loss: 0.5384 - accuracy: 0.6551 - val_loss: 0.5015 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "286/286 [==============================] - 7s 26ms/step - loss: 0.5071 - accuracy: 0.6748 - val_loss: 0.3527 - val_accuracy: 0.7779\n",
            "Epoch 14/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.4765 - accuracy: 0.6842 - val_loss: 0.4008 - val_accuracy: 0.7516\n",
            "Epoch 15/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.4584 - accuracy: 0.7014 - val_loss: 0.3467 - val_accuracy: 0.7737\n",
            "Epoch 16/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.4428 - accuracy: 0.7059 - val_loss: 0.2869 - val_accuracy: 0.8385\n",
            "Epoch 17/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.4213 - accuracy: 0.7278 - val_loss: 0.2778 - val_accuracy: 0.8433\n",
            "Epoch 18/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.4013 - accuracy: 0.7284 - val_loss: 0.2436 - val_accuracy: 0.8451\n",
            "Epoch 19/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.3864 - accuracy: 0.7436 - val_loss: 0.2290 - val_accuracy: 0.8558\n",
            "Epoch 20/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.3615 - accuracy: 0.7579 - val_loss: 0.2190 - val_accuracy: 0.8523\n",
            "Epoch 21/100\n",
            "286/286 [==============================] - 7s 25ms/step - loss: 0.3540 - accuracy: 0.7622 - val_loss: 0.2208 - val_accuracy: 0.8613\n",
            "Epoch 22/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.3429 - accuracy: 0.7695 - val_loss: 0.1960 - val_accuracy: 0.8816\n",
            "Epoch 23/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.3306 - accuracy: 0.7744 - val_loss: 0.2033 - val_accuracy: 0.8705\n",
            "Epoch 24/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.3171 - accuracy: 0.7833 - val_loss: 0.2197 - val_accuracy: 0.8685\n",
            "Epoch 25/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.3053 - accuracy: 0.7913 - val_loss: 0.1794 - val_accuracy: 0.8921\n",
            "Epoch 26/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.2918 - accuracy: 0.7992 - val_loss: 0.1981 - val_accuracy: 0.8672\n",
            "Epoch 27/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.2766 - accuracy: 0.8063 - val_loss: 0.1680 - val_accuracy: 0.8934\n",
            "Epoch 28/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.2631 - accuracy: 0.8151 - val_loss: 0.1597 - val_accuracy: 0.9088\n",
            "Epoch 29/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.2549 - accuracy: 0.8215 - val_loss: 0.1732 - val_accuracy: 0.8845\n",
            "Epoch 30/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.2418 - accuracy: 0.8291 - val_loss: 0.1504 - val_accuracy: 0.9123\n",
            "Epoch 31/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.2321 - accuracy: 0.8349 - val_loss: 0.1743 - val_accuracy: 0.8873\n",
            "Epoch 32/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.2238 - accuracy: 0.8366 - val_loss: 0.1648 - val_accuracy: 0.8974\n",
            "Epoch 33/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.2194 - accuracy: 0.8426 - val_loss: 0.1620 - val_accuracy: 0.8814\n",
            "Epoch 34/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.2068 - accuracy: 0.8500 - val_loss: 0.1614 - val_accuracy: 0.8923\n",
            "Epoch 35/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.2049 - accuracy: 0.8507 - val_loss: 0.1628 - val_accuracy: 0.8801\n",
            "Epoch 36/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1896 - accuracy: 0.8587 - val_loss: 0.1416 - val_accuracy: 0.9077\n",
            "Epoch 37/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.1914 - accuracy: 0.8568 - val_loss: 0.1712 - val_accuracy: 0.8867\n",
            "Epoch 38/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1817 - accuracy: 0.8638 - val_loss: 0.2279 - val_accuracy: 0.8495\n",
            "Epoch 39/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1789 - accuracy: 0.8657 - val_loss: 0.1630 - val_accuracy: 0.8869\n",
            "Epoch 40/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.1740 - accuracy: 0.8685 - val_loss: 0.1525 - val_accuracy: 0.8926\n",
            "Epoch 41/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1695 - accuracy: 0.8720 - val_loss: 0.1598 - val_accuracy: 0.8888\n",
            "Epoch 42/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1645 - accuracy: 0.8750 - val_loss: 0.1819 - val_accuracy: 0.8851\n",
            "Epoch 43/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1605 - accuracy: 0.8773 - val_loss: 0.1910 - val_accuracy: 0.8698\n",
            "Epoch 44/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1575 - accuracy: 0.8775 - val_loss: 0.1624 - val_accuracy: 0.8908\n",
            "Epoch 45/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.1538 - accuracy: 0.8831 - val_loss: 0.1876 - val_accuracy: 0.8796\n",
            "Epoch 46/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1496 - accuracy: 0.8845 - val_loss: 0.1333 - val_accuracy: 0.9068\n",
            "Epoch 47/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1471 - accuracy: 0.8879 - val_loss: 0.1658 - val_accuracy: 0.8886\n",
            "Epoch 48/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1420 - accuracy: 0.8949 - val_loss: 0.1456 - val_accuracy: 0.9048\n",
            "Epoch 49/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1374 - accuracy: 0.8933 - val_loss: 0.3043 - val_accuracy: 0.8066\n",
            "Epoch 50/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1362 - accuracy: 0.8918 - val_loss: 0.1694 - val_accuracy: 0.8853\n",
            "Epoch 51/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1328 - accuracy: 0.8941 - val_loss: 0.1422 - val_accuracy: 0.9094\n",
            "Epoch 52/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1288 - accuracy: 0.9003 - val_loss: 0.1833 - val_accuracy: 0.8860\n",
            "Epoch 53/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1257 - accuracy: 0.8993 - val_loss: 0.1438 - val_accuracy: 0.9046\n",
            "Epoch 54/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1247 - accuracy: 0.8990 - val_loss: 0.1559 - val_accuracy: 0.8945\n",
            "Epoch 55/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1252 - accuracy: 0.9011 - val_loss: 0.1423 - val_accuracy: 0.9048\n",
            "Epoch 56/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1265 - accuracy: 0.9016 - val_loss: 0.2008 - val_accuracy: 0.8770\n",
            "Epoch 57/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1139 - accuracy: 0.9114 - val_loss: 0.2261 - val_accuracy: 0.8755\n",
            "Epoch 58/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1128 - accuracy: 0.9107 - val_loss: 0.1292 - val_accuracy: 0.9112\n",
            "Epoch 59/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1168 - accuracy: 0.9074 - val_loss: 0.1621 - val_accuracy: 0.8941\n",
            "Epoch 60/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1099 - accuracy: 0.9123 - val_loss: 0.2074 - val_accuracy: 0.8825\n",
            "Epoch 61/100\n",
            "286/286 [==============================] - 7s 24ms/step - loss: 0.1101 - accuracy: 0.9137 - val_loss: 0.1972 - val_accuracy: 0.8731\n",
            "Epoch 62/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.1061 - accuracy: 0.9158 - val_loss: 0.1779 - val_accuracy: 0.8915\n",
            "Epoch 63/100\n",
            "286/286 [==============================] - 6s 23ms/step - loss: 0.1027 - accuracy: 0.9171 - val_loss: 0.1685 - val_accuracy: 0.8926\n",
            "Epoch 64/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0948 - accuracy: 0.9218 - val_loss: 0.1910 - val_accuracy: 0.8899\n",
            "Epoch 65/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.1003 - accuracy: 0.9205 - val_loss: 0.2031 - val_accuracy: 0.8873\n",
            "Epoch 66/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0979 - accuracy: 0.9186 - val_loss: 0.1952 - val_accuracy: 0.8836\n",
            "Epoch 67/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0968 - accuracy: 0.9221 - val_loss: 0.1967 - val_accuracy: 0.8834\n",
            "Epoch 68/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0899 - accuracy: 0.9255 - val_loss: 0.2278 - val_accuracy: 0.8799\n",
            "Epoch 69/100\n",
            "286/286 [==============================] - 7s 25ms/step - loss: 0.0906 - accuracy: 0.9260 - val_loss: 0.1953 - val_accuracy: 0.8829\n",
            "Epoch 70/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0887 - accuracy: 0.9280 - val_loss: 0.2995 - val_accuracy: 0.8335\n",
            "Epoch 71/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0861 - accuracy: 0.9277 - val_loss: 0.1983 - val_accuracy: 0.8790\n",
            "Epoch 72/100\n",
            "286/286 [==============================] - 6s 22ms/step - loss: 0.0895 - accuracy: 0.9277 - val_loss: 0.1577 - val_accuracy: 0.9125\n",
            "Epoch 73/100\n",
            "286/286 [==============================] - 7s 23ms/step - loss: 0.0838 - accuracy: 0.9327 - val_loss: 0.1824 - val_accuracy: 0.8969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 검증"
      ],
      "metadata": {
        "id": "-si1Z4G6j7mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_test = model.predict([sequences_up_test, sequences_down_test, scaled_data_test])\n",
        "\n",
        "predicted_classes = np.argmax(predict_test, axis=1)"
      ],
      "metadata": {
        "id": "sjrrYs6Yx9iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0983bcf8-7c58-41ed-a718-dc9ea7d4998c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 2s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 예측 결과(predicted_labels)와 실제 레이블(true_labels) 비교\n",
        "accuracy = accuracy_score(labels_test, predicted_classes)\n",
        "f1_score = f1_score(labels_test, predicted_classes, average = 'weighted')\n",
        "\n",
        "print(f'accuracy : {accuracy:.3f}\\nF1-score : {f1_score:.3f}')"
      ],
      "metadata": {
        "id": "otk-hzgzyFDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c431b60-e5e5-4f2d-f53e-a28eb351ec6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.908\n",
            "F1-score : 0.908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model.save('20230727_final_model.h5')"
      ],
      "metadata": {
        "id": "7k81nX22yF95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras.utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixpyWHbyovvk",
        "outputId": "5cd4ed4b-7551-444f-91ac-1b5022f78441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from keras.utils) (2.12.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2634 sha256=a30de77a66253546f9379ba310dd4d31c8f013d14a17645bf0151be1da4d1b60\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/c0/b3/0c332de4fd71f3733ea6d61697464b7ae4b2b5ff0300e6ca7a\n",
            "Successfully built keras.utils\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3099, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info. Did you mean: 'egg_info'?\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3119, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in _parsed_pkg_info\n",
            "    metadata = self.get_metadata(self.PKG_INFO)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1517, in get_metadata\n",
            "    value = self._get(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1727, in _get\n",
            "    return stream.read()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# 시각화할 모델의 구조를 가져옵니다.\n",
        "model_structure = model_to_dot(model, show_shapes=True)\n",
        "\n",
        "# SVG 형식으로 이미지를 생성합니다.\n",
        "svg_image = SVG(model_structure.create(prog='dot', format='svg'))\n",
        "\n",
        "display(svg_image)\n",
        "\n",
        "# 모델 구조를 이미지 파일로 저장합니다.\n",
        "plot_model(model, show_shapes=True, to_file='model_structure.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "hoaI3oq9Abc4",
        "outputId": "e5c7ff89-0d12-4c72-a35b-ef11e9c9c4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b1ba601036e2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 시각화할 모델의 구조를 가져옵니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# SVG 형식으로 이미지를 생성합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}