{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bok-h22/TIL-202303/blob/master/02_Text_Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문장 토큰화"
      ],
      "metadata": {
        "id": "-fxKPA2mNY2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7GmoJhbNl10",
        "outputId": "7be1e726-5cd9-4a5c-89c6-e68a61b3832e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
      ],
      "metadata": {
        "id": "7Kt5U_FaNp8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kew85hQbN2ns",
        "outputId": "a142ad46-afb8-4bcf-d158-f3c7826ae139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I never thought through love we'd be.\",\n",
              " 'Making one as lovely as she.',\n",
              " \"But isn't she lovely made from love.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras의 Tokenizer 사용하기\n",
        "- 정수 인코딩\n",
        "- 디코딩 지원\n",
        "- 단어 토큰화 지원"
      ],
      "metadata": {
        "id": "hzXlYEQXOQL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "OW2y-lYTOpB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코퍼스를 이용해서 단어 집합을 만들 수 있도록 훈련\n",
        "tokenizer.fit_on_texts(sent_tokenize(text))"
      ],
      "metadata": {
        "id": "JpEvf-ZrOxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 단어집합 확인\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awMy3pocPDgO",
        "outputId": "63415a12-bad0-43ef-e8e6-f841c4526fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love': 1,\n",
              " 'as': 2,\n",
              " 'lovely': 3,\n",
              " 'she': 4,\n",
              " 'i': 5,\n",
              " 'never': 6,\n",
              " 'thought': 7,\n",
              " 'through': 8,\n",
              " \"we'd\": 9,\n",
              " 'be': 10,\n",
              " 'making': 11,\n",
              " 'one': 12,\n",
              " 'but': 13,\n",
              " \"isn't\": 14,\n",
              " 'made': 15,\n",
              " 'from': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어의 빈도수 확인\n",
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-Rsn1wsPabl",
        "outputId": "d630a4d0-a7a8-4ed1-f05b-61b0ed97ea0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('i', 1),\n",
              "             ('never', 1),\n",
              "             ('thought', 1),\n",
              "             ('through', 1),\n",
              "             ('love', 2),\n",
              "             (\"we'd\", 1),\n",
              "             ('be', 1),\n",
              "             ('making', 1),\n",
              "             ('one', 1),\n",
              "             ('as', 2),\n",
              "             ('lovely', 2),\n",
              "             ('she', 2),\n",
              "             ('but', 1),\n",
              "             (\"isn't\", 1),\n",
              "             ('made', 1),\n",
              "             ('from', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩\n",
        "corpus = [\"she isn't lovely but i love she\"]\n",
        "print(tokenizer.texts_to_sequences(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hehxDlvPPqhb",
        "outputId": "513c6aac-a4f4-4a52-8e61-d62117145f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 14, 3, 13, 5, 1, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코딩\n",
        "print(tokenizer.sequences_to_texts([[5, 1, 6, 14, 16, 8, 10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgkwLJYQQPZu",
        "outputId": "2fbe91b6-d21e-4089-c27a-cc19bf202a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"i love never isn't from through be\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOV(Out Of Vocabulary) 설정"
      ],
      "metadata": {
        "id": "h8c0dSFyQjN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합의 크기 : vocab_size\n",
        "vocab_size = 5\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size+2, oov_token=\"<oov>\") # 실제 사용할 단어집합 5개 + pad, oov 토큰 개수까지 포함\n",
        "tokenizer.fit_on_texts(sent_tokenize(text))"
      ],
      "metadata": {
        "id": "QAKoY64iTK3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H93G3ASrT-Yb",
        "outputId": "c6e8105c-4a26-4cd2-f32e-eded456c740f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<oov>': 1,\n",
              " 'love': 2,\n",
              " 'as': 3,\n",
              " 'lovely': 4,\n",
              " 'she': 5,\n",
              " 'i': 6,\n",
              " 'never': 7,\n",
              " 'thought': 8,\n",
              " 'through': 9,\n",
              " \"we'd\": 10,\n",
              " 'be': 11,\n",
              " 'making': 12,\n",
              " 'one': 13,\n",
              " 'but': 14,\n",
              " \"isn't\": 15,\n",
              " 'made': 16,\n",
              " 'from': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"she is bowwow\"]\n",
        "tokenizer.texts_to_sequences(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t75dbIEUCSy",
        "outputId": "ae6c6ea5-e887-4b62-c705-ef1e95990649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "sHxRfi_CUVq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integer_tokens = tokenizer.texts_to_sequences(corpus)\n",
        "integer_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVrK5kRBUgYZ",
        "outputId": "fd687cbf-cf57-4197-a830-7292e372b51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 기본은 pre padding\n",
        "padded_tokens = pad_sequences(integer_tokens, maxlen=5)\n",
        "padded_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKTFoIRXUn_R",
        "outputId": "c9b5b383-cb11-4f36-ed4d-883eaec75670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 5, 1, 1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = pad_sequences(integer_tokens, maxlen=5, padding='post')\n",
        "padded_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXjgC2VU1ZZ",
        "outputId": "331a72bb-cfb6-4754-ed6a-e5354f7fc131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 1, 1, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Vectorization"
      ],
      "metadata": {
        "id": "QW0mTAbCU5sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"I'm at a payphone trying to call home\n",
        "All of my change I spent on you\n",
        "Where have the times gone?\n",
        "Baby, it's all wrong\n",
        "Where are the plans we made for two?\n",
        "Yeah, I, I know it's hard to remember\n",
        "The people we used to be\n",
        "It's even harder to picture\n",
        "That you're not here next to me\n",
        "You say it's too late to make it\n",
        "But is it too late to try?\n",
        "And in our time that you wasted\n",
        "All of our bridges burned down\n",
        "I've wasted my nights\n",
        "You turned out the lights\n",
        "Now I'm paralyzed\n",
        "Still stuck in that time, when we called it love\n",
        "But even the sun sets in paradise\n",
        "I'm at a payphone, trying to call home\n",
        "All of my change I spent on you\n",
        "Where have the times gone?\n",
        "Baby, it's all wrong\n",
        "Where are the plans we made for two?\n",
        "If \"happy ever after\" did exist\n",
        "I would still be holding you like this\n",
        "All those fairy tales are full of shit\n",
        "One more fucking love song, I'll be sick, oh\n",
        "You turned your back on tomorrow\n",
        "'Cause you forgot yesterday\n",
        "I gave you my love to borrow\n",
        "But you just gave it away\n",
        "You can't expect me to be fine\n",
        "I don't expect you to care\n",
        "I know I've said it before\n",
        "But all of our bridges burned down\n",
        "I've wasted my nights\n",
        "You turned out the lights\n",
        "Now I'm paralyzed\n",
        "Still stuck in that time\n",
        "When we called it love\n",
        "But even the sun sets in paradise\n",
        "I'm at a payphone trying to call home\n",
        "All of my change I spent on you\n",
        "Where have the times gone?\n",
        "Baby, it's all wrong\n",
        "Where are the plans we made for two?\n",
        "If \"happy ever after\" did exist\n",
        "I would still be holding you like this\n",
        "And all those fairy tales are full of shit\n",
        "One more fucking love song, I'll be sick\n",
        "Now I'm at a payphone\n",
        "Man, fuck that shit\n",
        "I'll be out spending all this money while you sitting round\n",
        "Wondering why wasn't you who came up from nothing\n",
        "Made it from the bottom, now when you see me I'm strutting\n",
        "And all of my cars start with a push of a button\n",
        "Telling me the chances I blew up or whatever you call it\n",
        "Switched the number to my phone so you never could call it\n",
        "Don't need my name on my show you can tell it I'm ballin'\n",
        "Swish, what a shame could have got picked\n",
        "Had a really good game but you missed your last shot\n",
        "So you talk about who you see at the top\n",
        "Or what you could have saw, but sad to say it's over for\n",
        "Phantom pulled valet open doors\n",
        "Wiz like go away got what you was looking for\n",
        "Now it's me who they want, so you can go\n",
        "And take that little piece of shit with you\n",
        "I'm at a payphone, trying to call home\n",
        "All of my change I spent on you\n",
        "Where have the times gone?\n",
        "Baby, it's all wrong\n",
        "Where are the plans we made for two?\n",
        "If \"happy ever after\" did exist\n",
        "I would still be holding you like this\n",
        "All those fairy tales are full of shit\n",
        "One more fucking love song, I'll be sick\n",
        "Now I'm at a payphone\"\"\"\n",
        "\n",
        "text2 = \"\"\"Spent 24 hours, I need more hours with you\n",
        "You spent the weekend getting even, ooh\n",
        "We spent the late nights making things right between us\n",
        "But now it's all good, babe\n",
        "Roll that back wood, babe\n",
        "And play me close\n",
        "'Cause girls like you run 'round with guys like me\n",
        "'Til sun down when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Girls like you love fun and, yeah, me too\n",
        "What I want when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you\n",
        "I spent last night on the last flight to you (ey ya)\n",
        "Took a whole day up trying to get way up, ooh\n",
        "We spent the daylight trying to make things right between us\n",
        "But now it's all good, babe\n",
        "Roll that back wood, babe\n",
        "And play me close, yeah\n",
        "'Cause girls like you run 'round with guys like me\n",
        "'Til sun down when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Girls like you love fun and, yeah, me too\n",
        "What I want when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you, yeah yeah\n",
        "I need a girl like you, yeah yeah\n",
        "I need a girl like you\n",
        "Maybe it's 6:45\n",
        "Maybe I'm barely alive\n",
        "Maybe you've taken my shit for the last time, yeah\n",
        "Maybe I know that I'm drunk\n",
        "Maybe I know you're the one\n",
        "Maybe you thinking it's better if you drive\n",
        "Oh, 'cause girls like you run 'round with guys like me\n",
        "'Til sun down when I come through\n",
        "I need a girl like you, yeah\n",
        "'Cause girls like you run 'round with guys like me\n",
        "'Til sun down when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Girls like you love fun and, yeah, me too\n",
        "What I want when I come through\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you, yeah yeah\n",
        "Yeah yeah yeah, yeah yeah yeah\n",
        "I need a girl like you\"\"\""
      ],
      "metadata": {
        "id": "K7L4t2qKVTsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코퍼스 만들기\n",
        "corpus = [text1, text2]\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfCjoa56Vd9M",
        "outputId": "27c79baa-dc03-4b6d-aa0d-4b955db45cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DTM (Document Term Matrix)\n",
        "- 문장 내 단어의 빈도\n"
      ],
      "metadata": {
        "id": "f2jVcRqXV4na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cnt_vector = CountVectorizer()\n",
        "cnt_vector.fit(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Xt9GfxeXWFCx",
        "outputId": "693a86a0-d532-4e2e-80ac-7390a9f5d58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vector = cnt_vector.transform(corpus)\n",
        "feature_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIEhkBuKWUbJ",
        "outputId": "d96ca9ff-5ce7-401a-b817-97218f62ee47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2x225 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 271 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vector.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfmN3Wf7WsE4",
        "outputId": "68d4922e-0df5-4f7c-e922-6987e6af905e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1,  3,  0, 15,  4,  7,  7,  2,  0,  4,  1,  1,  0,  9,\n",
              "         1,  0,  0,  1,  1,  1,  2,  2,  7,  1,  6,  2,  1,  3,  1,  1,\n",
              "         1,  1,  4,  0,  0,  3,  0,  0,  3,  2,  1,  2,  0,  0,  3,  3,\n",
              "         3,  2,  0,  3,  1,  0,  6,  1,  2,  1,  3,  3,  0,  1,  2,  0,\n",
              "         0,  0,  0,  2,  4,  1,  2,  0,  1,  3,  1,  1,  6,  1,  3,  4,\n",
              "         0,  3,  5,  1, 19,  1,  2,  1,  2,  2,  4,  1,  4,  1,  6,  5,\n",
              "         1,  0,  1,  0,  5,  1,  1,  3, 11,  1,  1,  1,  1,  0,  2,  1,\n",
              "         1,  6,  1, 12,  1,  6,  3,  0,  1,  2,  3,  3,  1,  2,  2,  6,\n",
              "         1,  1,  1,  1,  1,  1,  4,  0,  1,  1,  1,  1,  1,  0,  0,  1,\n",
              "         0,  1,  1,  1,  2,  2,  2,  1,  5,  1,  1,  3,  1,  3,  3,  1,\n",
              "         4,  1,  5,  1,  2,  2,  1,  1,  1,  0,  3,  1,  1,  1,  6, 17,\n",
              "         1,  0,  0,  4,  3,  0,  0,  3,  4, 15,  1,  2,  0,  1,  1,  4,\n",
              "         3,  4,  2,  0,  1,  1,  3,  1,  1,  1,  3,  0,  7,  0,  3,  1,\n",
              "         3,  8,  1,  3,  0,  1,  2,  1,  1,  0,  3,  4,  0,  1,  1, 31,\n",
              "         2],\n",
              "       [ 1,  1,  0,  0,  1,  2,  5,  0,  0,  0,  4,  0,  2,  0,  1,  0,\n",
              "         0,  1,  2,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,\n",
              "         4,  0,  0,  2,  7,  0,  1,  1,  0,  0,  0,  4,  1,  1,  1,  0,\n",
              "         0,  0,  1,  0,  0,  1,  1,  0,  0,  0,  0,  0,  3,  0,  0,  1,\n",
              "         1, 15,  7,  0,  0,  2,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         2,  1,  0,  0,  4,  0,  2,  3,  1,  0, 26,  0,  0,  0,  3,  0,\n",
              "         1,  1,  0,  6,  9,  0,  0,  1,  1,  0, 16,  0,  0,  1,  1,  0,\n",
              "         0,  2,  0,  0,  1,  1,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  1,  0,  0,  2,  2,  4,\n",
              "         4,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
              "         5,  0,  0,  0,  0,  4,  0,  0,  0,  1,  0,  0,  0,  0,  3,  6,\n",
              "         0,  2,  1,  0,  0,  7,  4,  1,  0,  3,  0,  3,  1,  0,  0,  2,\n",
              "         0,  0,  2,  2,  0,  0,  1,  3,  0,  0,  0,  1,  2,  1,  3,  0,\n",
              "         7,  0,  0,  0,  1,  0,  5,  0,  0,  2,  0,  0,  1, 64,  0, 29,\n",
              "         0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 단어 확인\n",
        "vocabs = sorted(cnt_vector.vocabulary_.items()) # 단어 순서대로 정렬\n",
        "vocabs = [ item[0] for item in vocabs ] # 단어만 뽑아내기\n",
        "\n",
        "dtm = pd.DataFrame(\n",
        "    columns=vocabs,\n",
        "    data=feature_vector.toarray()\n",
        ")\n",
        "dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "FAIVSBCvW49h",
        "outputId": "20c14f6b-c769-4cc0-ee63-f769fb56f470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   24  45  about  after  alive  all  ...  wrong  ya  yeah  yesterday  you  your\n",
              "0   0   0      1      3      0   15  ...      4   0     1          1   31     2\n",
              "1   1   1      0      0      1    2  ...      0   1    64          0   29     0\n",
              "\n",
              "[2 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-276b843e-ce03-4686-9c78-b45e95424fc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>24</th>\n",
              "      <th>45</th>\n",
              "      <th>about</th>\n",
              "      <th>after</th>\n",
              "      <th>alive</th>\n",
              "      <th>all</th>\n",
              "      <th>and</th>\n",
              "      <th>are</th>\n",
              "      <th>at</th>\n",
              "      <th>away</th>\n",
              "      <th>babe</th>\n",
              "      <th>baby</th>\n",
              "      <th>back</th>\n",
              "      <th>ballin</th>\n",
              "      <th>barely</th>\n",
              "      <th>be</th>\n",
              "      <th>before</th>\n",
              "      <th>better</th>\n",
              "      <th>between</th>\n",
              "      <th>blew</th>\n",
              "      <th>borrow</th>\n",
              "      <th>bottom</th>\n",
              "      <th>bridges</th>\n",
              "      <th>burned</th>\n",
              "      <th>but</th>\n",
              "      <th>button</th>\n",
              "      <th>call</th>\n",
              "      <th>called</th>\n",
              "      <th>came</th>\n",
              "      <th>can</th>\n",
              "      <th>care</th>\n",
              "      <th>cars</th>\n",
              "      <th>cause</th>\n",
              "      <th>chances</th>\n",
              "      <th>change</th>\n",
              "      <th>close</th>\n",
              "      <th>come</th>\n",
              "      <th>could</th>\n",
              "      <th>day</th>\n",
              "      <th>daylight</th>\n",
              "      <th>...</th>\n",
              "      <th>to</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>too</th>\n",
              "      <th>took</th>\n",
              "      <th>top</th>\n",
              "      <th>try</th>\n",
              "      <th>trying</th>\n",
              "      <th>turned</th>\n",
              "      <th>two</th>\n",
              "      <th>up</th>\n",
              "      <th>us</th>\n",
              "      <th>used</th>\n",
              "      <th>valet</th>\n",
              "      <th>ve</th>\n",
              "      <th>want</th>\n",
              "      <th>was</th>\n",
              "      <th>wasn</th>\n",
              "      <th>wasted</th>\n",
              "      <th>way</th>\n",
              "      <th>we</th>\n",
              "      <th>weekend</th>\n",
              "      <th>what</th>\n",
              "      <th>whatever</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>who</th>\n",
              "      <th>whole</th>\n",
              "      <th>why</th>\n",
              "      <th>with</th>\n",
              "      <th>wiz</th>\n",
              "      <th>wondering</th>\n",
              "      <th>wood</th>\n",
              "      <th>would</th>\n",
              "      <th>wrong</th>\n",
              "      <th>ya</th>\n",
              "      <th>yeah</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 225 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-276b843e-ce03-4686-9c78-b45e95424fc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-276b843e-ce03-4686-9c78-b45e95424fc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-276b843e-ce03-4686-9c78-b45e95424fc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "-IzRPh5CXFjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "j4tDBrAQXr0S",
        "outputId": "3ea19a0d-243f-4d33-cd26-758a1bc10882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vect = tfidf_vect.transform(corpus)\n",
        "feature_vect.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H87m-CdiX52p",
        "outputId": "6c7c2449-3d72-43c4-df24-64c8e3382e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.02024321, 0.06072962, 0.        ,\n",
              "        0.21604811, 0.05761283, 0.14170244, 0.14170244, 0.04048641,\n",
              "        0.        , 0.08097282, 0.01440321, 0.02024321, 0.        ,\n",
              "        0.18218885, 0.02024321, 0.        , 0.        , 0.02024321,\n",
              "        0.02024321, 0.02024321, 0.04048641, 0.04048641, 0.10082245,\n",
              "        0.02024321, 0.12145923, 0.04048641, 0.02024321, 0.06072962,\n",
              "        0.02024321, 0.02024321, 0.01440321, 0.02024321, 0.08097282,\n",
              "        0.        , 0.        , 0.06072962, 0.        , 0.        ,\n",
              "        0.06072962, 0.04048641, 0.02024321, 0.02880641, 0.        ,\n",
              "        0.        , 0.04320962, 0.06072962, 0.06072962, 0.04048641,\n",
              "        0.        , 0.06072962, 0.02024321, 0.        , 0.08641924,\n",
              "        0.02024321, 0.04048641, 0.02024321, 0.06072962, 0.06072962,\n",
              "        0.        , 0.02024321, 0.04048641, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04048641, 0.08097282, 0.01440321,\n",
              "        0.04048641, 0.        , 0.02024321, 0.06072962, 0.02024321,\n",
              "        0.02024321, 0.12145923, 0.02024321, 0.06072962, 0.08097282,\n",
              "        0.        , 0.04320962, 0.10121603, 0.02024321, 0.27366094,\n",
              "        0.02024321, 0.02880641, 0.01440321, 0.02880641, 0.04048641,\n",
              "        0.05761283, 0.02024321, 0.08097282, 0.02024321, 0.08641924,\n",
              "        0.10121603, 0.01440321, 0.        , 0.02024321, 0.        ,\n",
              "        0.07201604, 0.02024321, 0.02024321, 0.04320962, 0.15843528,\n",
              "        0.02024321, 0.01440321, 0.02024321, 0.02024321, 0.        ,\n",
              "        0.02880641, 0.02024321, 0.02024321, 0.08641924, 0.02024321,\n",
              "        0.24291846, 0.01440321, 0.08641924, 0.04320962, 0.        ,\n",
              "        0.02024321, 0.04048641, 0.06072962, 0.06072962, 0.02024321,\n",
              "        0.04048641, 0.04048641, 0.12145923, 0.02024321, 0.02024321,\n",
              "        0.02024321, 0.02024321, 0.02024321, 0.02024321, 0.08097282,\n",
              "        0.        , 0.02024321, 0.02024321, 0.01440321, 0.02024321,\n",
              "        0.02024321, 0.        , 0.        , 0.01440321, 0.        ,\n",
              "        0.02024321, 0.02024321, 0.02024321, 0.04048641, 0.04048641,\n",
              "        0.04048641, 0.02024321, 0.07201604, 0.02024321, 0.02024321,\n",
              "        0.06072962, 0.02024321, 0.06072962, 0.06072962, 0.02024321,\n",
              "        0.05761283, 0.02024321, 0.10121603, 0.02024321, 0.04048641,\n",
              "        0.02880641, 0.02024321, 0.02024321, 0.02024321, 0.        ,\n",
              "        0.06072962, 0.02024321, 0.02024321, 0.02024321, 0.08641924,\n",
              "        0.24485452, 0.02024321, 0.        , 0.        , 0.08097282,\n",
              "        0.06072962, 0.        , 0.        , 0.04320962, 0.08097282,\n",
              "        0.21604811, 0.02024321, 0.02880641, 0.        , 0.02024321,\n",
              "        0.02024321, 0.05761283, 0.06072962, 0.08097282, 0.02880641,\n",
              "        0.        , 0.02024321, 0.02024321, 0.04320962, 0.01440321,\n",
              "        0.02024321, 0.02024321, 0.06072962, 0.        , 0.10082245,\n",
              "        0.        , 0.04320962, 0.02024321, 0.04320962, 0.16194564,\n",
              "        0.02024321, 0.06072962, 0.        , 0.02024321, 0.02880641,\n",
              "        0.02024321, 0.02024321, 0.        , 0.06072962, 0.08097282,\n",
              "        0.        , 0.01440321, 0.02024321, 0.44649942, 0.04048641],\n",
              "       [0.01636409, 0.01636409, 0.        , 0.        , 0.01636409,\n",
              "        0.02328637, 0.05821592, 0.        , 0.        , 0.        ,\n",
              "        0.06545635, 0.        , 0.02328637, 0.        , 0.01636409,\n",
              "        0.        , 0.        , 0.01636409, 0.03272818, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.02328637,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04657273, 0.        , 0.        ,\n",
              "        0.03272818, 0.11454861, 0.        , 0.01636409, 0.01636409,\n",
              "        0.        , 0.        , 0.        , 0.04657273, 0.01636409,\n",
              "        0.01636409, 0.01164318, 0.        , 0.        , 0.        ,\n",
              "        0.01636409, 0.        , 0.        , 0.01636409, 0.01164318,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04909226, 0.        , 0.        , 0.01636409, 0.01636409,\n",
              "        0.24546131, 0.11454861, 0.        , 0.        , 0.02328637,\n",
              "        0.        , 0.06545635, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03272818, 0.01164318, 0.        , 0.        , 0.04657273,\n",
              "        0.        , 0.02328637, 0.03492955, 0.01164318, 0.        ,\n",
              "        0.30272276, 0.        , 0.        , 0.        , 0.03492955,\n",
              "        0.        , 0.01164318, 0.01636409, 0.        , 0.09818453,\n",
              "        0.10478865, 0.        , 0.        , 0.01164318, 0.01164318,\n",
              "        0.        , 0.18629093, 0.        , 0.        , 0.01636409,\n",
              "        0.01164318, 0.        , 0.        , 0.02328637, 0.        ,\n",
              "        0.        , 0.01164318, 0.01164318, 0.01164318, 0.03272818,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03272818, 0.        , 0.        , 0.01164318, 0.        ,\n",
              "        0.        , 0.03272818, 0.03272818, 0.04657273, 0.06545635,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01164318, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05821592, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04657273, 0.        , 0.        , 0.        , 0.01636409,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.03492955,\n",
              "        0.0698591 , 0.        , 0.03272818, 0.01636409, 0.        ,\n",
              "        0.        , 0.11454861, 0.06545635, 0.01164318, 0.        ,\n",
              "        0.03492955, 0.        , 0.03492955, 0.01636409, 0.        ,\n",
              "        0.        , 0.02328637, 0.        , 0.        , 0.02328637,\n",
              "        0.03272818, 0.        , 0.        , 0.01164318, 0.03492955,\n",
              "        0.        , 0.        , 0.        , 0.01636409, 0.02328637,\n",
              "        0.01636409, 0.03492955, 0.        , 0.08150228, 0.        ,\n",
              "        0.        , 0.        , 0.01636409, 0.        , 0.05821592,\n",
              "        0.        , 0.        , 0.03272818, 0.        , 0.        ,\n",
              "        0.01636409, 0.74516371, 0.        , 0.33765231, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = sorted(tfidf_vect.vocabulary_.items()) # 단어 순서대로 정렬\n",
        "vocabs = [ item[0] for item in vocabs ] # 단어만 뽑아내기\n",
        "\n",
        "tfidf = pd.DataFrame(\n",
        "    columns=vocabs,\n",
        "    data=feature_vect.toarray()\n",
        ")\n",
        "\n",
        "tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "hzQxvDg-YGWp",
        "outputId": "80c5323e-7eaa-4c26-d5df-f5d43970f9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         24        45     about  ...  yesterday       you      your\n",
              "0  0.000000  0.000000  0.020243  ...   0.020243  0.446499  0.040486\n",
              "1  0.016364  0.016364  0.000000  ...   0.000000  0.337652  0.000000\n",
              "\n",
              "[2 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98d661e6-e6bc-4c21-8469-2d4942e75d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>24</th>\n",
              "      <th>45</th>\n",
              "      <th>about</th>\n",
              "      <th>after</th>\n",
              "      <th>alive</th>\n",
              "      <th>all</th>\n",
              "      <th>and</th>\n",
              "      <th>are</th>\n",
              "      <th>at</th>\n",
              "      <th>away</th>\n",
              "      <th>babe</th>\n",
              "      <th>baby</th>\n",
              "      <th>back</th>\n",
              "      <th>ballin</th>\n",
              "      <th>barely</th>\n",
              "      <th>be</th>\n",
              "      <th>before</th>\n",
              "      <th>better</th>\n",
              "      <th>between</th>\n",
              "      <th>blew</th>\n",
              "      <th>borrow</th>\n",
              "      <th>bottom</th>\n",
              "      <th>bridges</th>\n",
              "      <th>burned</th>\n",
              "      <th>but</th>\n",
              "      <th>button</th>\n",
              "      <th>call</th>\n",
              "      <th>called</th>\n",
              "      <th>came</th>\n",
              "      <th>can</th>\n",
              "      <th>care</th>\n",
              "      <th>cars</th>\n",
              "      <th>cause</th>\n",
              "      <th>chances</th>\n",
              "      <th>change</th>\n",
              "      <th>close</th>\n",
              "      <th>come</th>\n",
              "      <th>could</th>\n",
              "      <th>day</th>\n",
              "      <th>daylight</th>\n",
              "      <th>...</th>\n",
              "      <th>to</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>too</th>\n",
              "      <th>took</th>\n",
              "      <th>top</th>\n",
              "      <th>try</th>\n",
              "      <th>trying</th>\n",
              "      <th>turned</th>\n",
              "      <th>two</th>\n",
              "      <th>up</th>\n",
              "      <th>us</th>\n",
              "      <th>used</th>\n",
              "      <th>valet</th>\n",
              "      <th>ve</th>\n",
              "      <th>want</th>\n",
              "      <th>was</th>\n",
              "      <th>wasn</th>\n",
              "      <th>wasted</th>\n",
              "      <th>way</th>\n",
              "      <th>we</th>\n",
              "      <th>weekend</th>\n",
              "      <th>what</th>\n",
              "      <th>whatever</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>who</th>\n",
              "      <th>whole</th>\n",
              "      <th>why</th>\n",
              "      <th>with</th>\n",
              "      <th>wiz</th>\n",
              "      <th>wondering</th>\n",
              "      <th>wood</th>\n",
              "      <th>would</th>\n",
              "      <th>wrong</th>\n",
              "      <th>ya</th>\n",
              "      <th>yeah</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216048</td>\n",
              "      <td>0.057613</td>\n",
              "      <td>0.141702</td>\n",
              "      <td>0.141702</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080973</td>\n",
              "      <td>0.014403</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.182189</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.100822</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.121459</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.014403</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.080973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216048</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.028806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.057613</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.080973</td>\n",
              "      <td>0.028806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.043210</td>\n",
              "      <td>0.014403</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.04321</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.043210</td>\n",
              "      <td>0.161946</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.028806</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.06073</td>\n",
              "      <td>0.080973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014403</td>\n",
              "      <td>0.020243</td>\n",
              "      <td>0.446499</td>\n",
              "      <td>0.040486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.058216</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.032728</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046573</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032728</td>\n",
              "      <td>0.114549</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034930</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.032728</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011643</td>\n",
              "      <td>0.034930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.023286</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.03493</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058216</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032728</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016364</td>\n",
              "      <td>0.745164</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.337652</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 225 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98d661e6-e6bc-4c21-8469-2d4942e75d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98d661e6-e6bc-4c21-8469-2d4942e75d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98d661e6-e6bc-4c21-8469-2d4942e75d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 벡터화된 텍스트 정보 활용"
      ],
      "metadata": {
        "id": "pVMKorHRYQ0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset='all', random_state=42)"
      ],
      "metadata": {
        "id": "mY2XWSnRYxhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target 확인\n",
        "news_data.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPMNsP0BZRgi",
        "outputId": "6bfea140-3cdb-4928-9683-0ee632285774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "print(news_data['data'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQSQ0u-HZiRg",
        "outputId": "806bef6a-e19b-46ea-ddff-7a485183eda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
            "Subject: Pens fans reactions\n",
            "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
            "Lines: 12\n",
            "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
            "\n",
            "\n",
            "\n",
            "I am sure some bashers of Pens fans are pretty confused about the lack\n",
            "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
            "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
            "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
            "are killing those Devils worse than I thought. Jagr just showed you why\n",
            "he is much better than his regular season stats. He is also a lot\n",
            "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
            "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
            "regular season game.          PENS RULE!!!\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_data['target'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfAVRQxaZ0iZ",
        "outputId": "607b77ac-3da3-4d0c-c316-05d1954a6c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 가져오기. header, footers, 특수문자를 제거하고 불러오기\n",
        "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=42)\n",
        "X_train = train_news['data']\n",
        "y_train = train_news['target']\n",
        "\n",
        "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=42)\n",
        "X_test = test_news['data']\n",
        "y_test = test_news['target']"
      ],
      "metadata": {
        "id": "sUQTqQcoZ6Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dFnnyKLaF8x",
        "outputId": "94871b23-69d9-4876-91a0-08ff11b6a16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.',\n",
              " \"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\",\n",
              " 'well folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf_vect = tfidf_vect.fit_transform(X_train)\n",
        "X_test_tfidf_vect  = tfidf_vect.transform(X_test)"
      ],
      "metadata": {
        "id": "fEuXJdUlaVgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)\n",
        "\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZDRcYG9a1cg",
        "outputId": "88bd667d-c538-4c2a-c0ea-34d54b56554a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6736590546999469"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_baseball_0427=\"\"\"CNN\n",
        " —\n",
        "It was one of those perfect, historic nights for Adolis García on Saturday as he slugged three home runs in his five hits and added eight runs as the Texas Rangers dismantled the Oakland Athletics 18-3.\n",
        "\n",
        "Each homer was projected at 400+ feet, combining for an incredible 1,252 feet of home run distance. It capped the Rangers’ dominant night, after they lost the series opener 5-4 on Friday, and marked a career-best performance for García as well as the first eight RBI game by a Ranger since Nelson Cruz more than a decade ago.\n",
        "\n",
        "“It was an incredible night for me,” García said through interpreter Raul Cardenas, according to MLB.com. “I didn’t expect something like this to happen, but I’m really blessed and thankful for it.\n",
        "\n",
        "“I was just looking for certain pitches, in a certain zone. I wasn’t trying to do too much and not overthinking it, just trying to make good contact.”\n",
        "\n",
        "It was an astonishing night for the right fielder. He hit a two-run home run in the first, letting it fly high into the crowd to tie the score, was hit by a pitch in the second, then hit another couple of two-run homers in the third and fifth.\"\"\"\n",
        "\n",
        "# tfidf vector 생성\n",
        "test_vector = tfidf_vect.transform([news_baseball_0427])\n",
        "\n",
        "# 예측\n",
        "lr_clf.predict(test_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzI7cnuUbZqH",
        "outputId": "f534360f-5927-42d5-c294-af28d516dc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6Mx3J3ncWyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}