{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "MC7DscGaZ-Xx"
      ],
      "mount_file_id": "12eqAnkih5Fz_c-ULt4fGUaWEFHCPxMH1",
      "authorship_tag": "ABX9TyOPQJh5Jz0uk7vzohJH8Pqe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bok-h22/TIL-202303/blob/master/BPE_RNN_%ED%9D%AC%EC%A4%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tokenizers\n",
        "#!pip install sentencepiece\n",
        "#!pip install focal_loss\n",
        "#!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "metadata": {
        "id": "x233XtPGg-xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "metadata": {
        "id": "j-EiFxmwjtuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2jKgXDGZjnh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vLeCfC8uiTf",
        "outputId": "24307d28-0255-4104-93e7-39677db95f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "LR_yLPR7uptf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input/rename\n",
        "data = pd.read_csv('/content/drive/MyDrive/한스펠 돌린 최종본.csv', encoding = 'utf-8')\n",
        "\n",
        "data= data.drop(data[data['cleand_up'].isna() == True].index)\n",
        "data= data.drop(data[data['cleand_down'].isna() == True].index)\n",
        "data = pd.concat([data, pd.get_dummies(data['corp'])], axis = 1)\n",
        "#data['label'] = data['label'].astype('str')"
      ],
      "metadata": {
        "id": "RMbOWIasZ7Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(data.drop(['Unnamed: 0', 'corp', 'stock_code', 'year', 'sector', 'rank'], axis = 1), test_size=0.25, stratify=data['label'].to_list())\n",
        "train_data, validation_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label'].to_list())"
      ],
      "metadata": {
        "id": "Im27npyuwPy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_review.txt', 'a', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(train_data['cleand_up']))\n",
        "    f.write('\\n'.join(train_data['cleand_down']))\n",
        "    f.write('\\n'.join(test_data['cleand_up']))\n",
        "    f.write('\\n'.join(test_data['cleand_down']))"
      ],
      "metadata": {
        "id": "Nwf1TZW7aEm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corp dummiies\n",
        "corp_train = np.array(train_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))\n",
        "corp_valid = np.array(validation_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))\n",
        "corp_test = np.array(test_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))"
      ],
      "metadata": {
        "id": "i_E6si2e0UXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import SentencePieceBPETokenizer\n",
        "\n",
        "tokenizer = SentencePieceBPETokenizer()\n",
        "tokenizer.train('test_review.txt', vocab_size=5000, min_frequency=3)\n",
        "\n",
        "# train\n",
        "train_data['sp_up_train'] = train_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "train_data['sp_down_train'] = train_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "train_data['re_up_train'] = train_data['sp_up_train'].apply(lambda x: tokenizer.decode(x))\n",
        "train_data['re_down_train'] = train_data['sp_down_train'].apply(lambda x: tokenizer.decode(x))\n",
        "\n",
        "#valid\n",
        "validation_data['sp_up_valid'] = validation_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "validation_data['sp_down_valid'] = validation_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "validation_data['re_up_valid'] = validation_data['sp_up_valid'].apply(lambda x: tokenizer.decode(x))\n",
        "validation_data['re_down_valid'] = validation_data['sp_down_valid'].apply(lambda x: tokenizer.decode(x))\n",
        "\n",
        "# test\n",
        "test_data['sp_up_test'] = test_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "test_data['sp_down_test'] = test_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "test_data['re_up_test'] = test_data['sp_up_test'].apply(lambda x: tokenizer.decode(x))\n",
        "test_data['re_down_test'] = test_data['sp_down_test'].apply(lambda x: tokenizer.decode(x))"
      ],
      "metadata": {
        "id": "1e1ZVsp6yIJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이즈\n",
        "tokenized_train = train_data['sp_down_train']\n",
        "tokenized_valid = validation_data['sp_down_valid']\n",
        "tokenized_test = test_data['sp_down_test']"
      ],
      "metadata": {
        "id": "xRMZI9zxjQM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 기술통계량\n",
        "train_cnt = pd.DataFrame([ len(tokenized_train.iloc[i]) for i in range(len(tokenized_train)) ], columns = ['train'])\n",
        "valid_cnt = pd.DataFrame([ len(tokenized_valid.iloc[i]) for i in range(len(tokenized_valid)) ], columns = ['valid'])\n",
        "test_cnt = pd.DataFrame([ len(tokenized_test.iloc[i]) for i in range(len(tokenized_test)) ], columns = ['test'])\n",
        "\n",
        "describe_1 = train_cnt.describe().values.tolist()\n",
        "describe_2 = valid_cnt.describe().values.tolist()\n",
        "describe_3 = test_cnt.describe().values.tolist()\n",
        "\n",
        "pd.DataFrame([describe_1, describe_2, describe_3], columns = train_cnt.describe().index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "OtU7vxMzjNrq",
        "outputId": "0a6fa262-0303-4347-e909-1df4d0ddf6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       count                  mean                  std    min     25%  \\\n",
              "0  [18395.0]  [23.012449035063877]  [20.25164636927158]  [4.0]  [14.0]   \n",
              "1   [4599.0]   [22.93889976081757]  [20.10819922636494]  [5.0]  [14.0]   \n",
              "2   [7665.0]   [22.64187866927593]  [18.05778952833602]  [3.0]  [14.0]   \n",
              "\n",
              "      50%     75%      max  \n",
              "0  [17.0]  [24.0]  [542.0]  \n",
              "1  [17.0]  [25.0]  [428.0]  \n",
              "2  [17.0]  [24.0]  [399.0]  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-657980dc-1594-435d-b611-302b11ef79ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[18395.0]</td>\n",
              "      <td>[23.012449035063877]</td>\n",
              "      <td>[20.25164636927158]</td>\n",
              "      <td>[4.0]</td>\n",
              "      <td>[14.0]</td>\n",
              "      <td>[17.0]</td>\n",
              "      <td>[24.0]</td>\n",
              "      <td>[542.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[4599.0]</td>\n",
              "      <td>[22.93889976081757]</td>\n",
              "      <td>[20.10819922636494]</td>\n",
              "      <td>[5.0]</td>\n",
              "      <td>[14.0]</td>\n",
              "      <td>[17.0]</td>\n",
              "      <td>[25.0]</td>\n",
              "      <td>[428.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7665.0]</td>\n",
              "      <td>[22.64187866927593]</td>\n",
              "      <td>[18.05778952833602]</td>\n",
              "      <td>[3.0]</td>\n",
              "      <td>[14.0]</td>\n",
              "      <td>[17.0]</td>\n",
              "      <td>[24.0]</td>\n",
              "      <td>[399.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657980dc-1594-435d-b611-302b11ef79ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3d06a9c2-07d9-47de-86c2-764d2fec49b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d06a9c2-07d9-47de-86c2-764d2fec49b2')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3d06a9c2-07d9-47de-86c2-764d2fec49b2 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-657980dc-1594-435d-b611-302b11ef79ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-657980dc-1594-435d-b611-302b11ef79ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "max_length = 50\n",
        "\n",
        "# train\n",
        "train_sequences = np.concatenate([pad_sequences(tokenized_train, maxlen=max_length, padding='post', truncating='post'), corp_train], axis = 1)\n",
        "labels_train = np.array(train_data['label'])\n",
        "\n",
        "# valid\n",
        "valid_sequences = np.concatenate([pad_sequences(tokenized_valid, maxlen=max_length, padding='post', truncating='post'), corp_valid], axis = 1)\n",
        "labels_valid = np.array(validation_data['label'])\n",
        "\n",
        "# test\n",
        "test_sequences = np.concatenate([pad_sequences(tokenized_test, maxlen=max_length, padding='post', truncating='post'), corp_test], axis = 1)\n",
        "labels_test = np.array(test_data['label'])"
      ],
      "metadata": {
        "id": "eaaXjY-Rd3Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0mAuLKA8moJ",
        "outputId": "48dbcc0f-2df1-489c-85fc-5bca5d417b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1052, 1622, 1808, ...,    0,    0,    0],\n",
              "       [2077, 1966, 1019, ...,    0,    0,    0],\n",
              "       [1018, 2204,  694, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [1042, 1157, 1213, ...,    0,    0,    0],\n",
              "       [1782,  695, 1276, ...,    0,    0,    0],\n",
              "       [2540,  737, 3232, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 우리의 모델"
      ],
      "metadata": {
        "id": "3pccZRVsNWQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, BatchNormalization\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define input layer\n",
        "input_layer = Input(shape=(max_length+len(data['corp'].unique()),))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.get_vocab()), output_dim=512, input_length=max_length)(input_layer)\n",
        "\n",
        "# LSTM layers\n",
        "gru_1 = GRU(256, activation='tanh', return_sequences=True)(embedding_layer)\n",
        "gru_2 = GRU(128, activation='tanh')(gru_1)\n",
        "\n",
        "# Dropout and BatchNormalization layers\n",
        "dropout_1 = Dropout(0.1)(gru_2)\n",
        "batchnorm_1 = BatchNormalization()(dropout_1)\n",
        "dense_1 = Dense(64, activation='relu')(batchnorm_1)\n",
        "\n",
        "dropout_2 = Dropout(0.1)(dense_1)\n",
        "batchnorm_2 = BatchNormalization()(dropout_2)\n",
        "dense_2 = Dense(32, activation='relu')(batchnorm_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(9, activation='softmax')(dense_2)\n",
        "\n",
        "# Create the functional model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Create an optimizer with a custom learning rate\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Focal Loss\n",
        "loss_func = SparseCategoricalFocalLoss(gamma=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkcaqn7sZmw6",
        "outputId": "ef6f3aef-0dbe-4736-e498-03adebdfb210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 226)]             0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 226, 512)          2560000   \n",
            "                                                                 \n",
            " gru_16 (GRU)                (None, 226, 256)          591360    \n",
            "                                                                 \n",
            " gru_17 (GRU)                (None, 128)               148224    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 9)                 297       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,310,985\n",
            "Trainable params: 3,310,601\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I5JX1KAzTqk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_sequences,\n",
        "                    labels_train,\n",
        "                    validation_data=(valid_sequences, labels_valid),\n",
        "                    verbose= 1,\n",
        "                    epochs=100,\n",
        "                    batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAnsgAPMaBsc",
        "outputId": "40654245-c5cf-47cd-d54b-f59c33963a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "288/288 [==============================] - 47s 144ms/step - loss: 2.0377 - accuracy: 0.1024 - val_loss: 1.7076 - val_accuracy: 0.1455\n",
            "Epoch 2/100\n",
            "288/288 [==============================] - 23s 80ms/step - loss: 1.7797 - accuracy: 0.1619 - val_loss: 1.5786 - val_accuracy: 0.1498\n",
            "Epoch 3/100\n",
            "288/288 [==============================] - 20s 68ms/step - loss: 1.6724 - accuracy: 0.1927 - val_loss: 1.6768 - val_accuracy: 0.2377\n",
            "Epoch 4/100\n",
            "288/288 [==============================] - 19s 64ms/step - loss: 1.6044 - accuracy: 0.2083 - val_loss: 1.5974 - val_accuracy: 0.1746\n",
            "Epoch 5/100\n",
            "288/288 [==============================] - 19s 66ms/step - loss: 1.5426 - accuracy: 0.2161 - val_loss: 1.5349 - val_accuracy: 0.1894\n",
            "Epoch 6/100\n",
            "288/288 [==============================] - 18s 64ms/step - loss: 1.4566 - accuracy: 0.2431 - val_loss: 1.3486 - val_accuracy: 0.2959\n",
            "Epoch 7/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 1.3727 - accuracy: 0.2830 - val_loss: 1.2910 - val_accuracy: 0.3449\n",
            "Epoch 8/100\n",
            "288/288 [==============================] - 18s 64ms/step - loss: 1.2705 - accuracy: 0.3243 - val_loss: 1.1577 - val_accuracy: 0.3686\n",
            "Epoch 9/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 1.1868 - accuracy: 0.3529 - val_loss: 1.0679 - val_accuracy: 0.3894\n",
            "Epoch 10/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 1.1284 - accuracy: 0.3766 - val_loss: 0.9935 - val_accuracy: 0.5112\n",
            "Epoch 11/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 1.0745 - accuracy: 0.4034 - val_loss: 0.9765 - val_accuracy: 0.4318\n",
            "Epoch 12/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 1.0293 - accuracy: 0.4244 - val_loss: 0.9528 - val_accuracy: 0.4177\n",
            "Epoch 13/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.9727 - accuracy: 0.4510 - val_loss: 0.8652 - val_accuracy: 0.5736\n",
            "Epoch 14/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.9217 - accuracy: 0.4814 - val_loss: 0.8495 - val_accuracy: 0.5319\n",
            "Epoch 15/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 0.8782 - accuracy: 0.5023 - val_loss: 0.7477 - val_accuracy: 0.6193\n",
            "Epoch 16/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.8175 - accuracy: 0.5383 - val_loss: 0.7481 - val_accuracy: 0.5582\n",
            "Epoch 17/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.7774 - accuracy: 0.5580 - val_loss: 0.6100 - val_accuracy: 0.6778\n",
            "Epoch 18/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.7195 - accuracy: 0.5871 - val_loss: 0.6035 - val_accuracy: 0.6569\n",
            "Epoch 19/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.6736 - accuracy: 0.6011 - val_loss: 0.5339 - val_accuracy: 0.6841\n",
            "Epoch 20/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.6417 - accuracy: 0.6135 - val_loss: 0.5113 - val_accuracy: 0.7021\n",
            "Epoch 21/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.6009 - accuracy: 0.6300 - val_loss: 0.5050 - val_accuracy: 0.6986\n",
            "Epoch 22/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.5739 - accuracy: 0.6442 - val_loss: 0.4635 - val_accuracy: 0.7245\n",
            "Epoch 23/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.5432 - accuracy: 0.6569 - val_loss: 0.4477 - val_accuracy: 0.7299\n",
            "Epoch 24/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.5156 - accuracy: 0.6712 - val_loss: 0.4156 - val_accuracy: 0.7476\n",
            "Epoch 25/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.4884 - accuracy: 0.6805 - val_loss: 0.4470 - val_accuracy: 0.7130\n",
            "Epoch 26/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.4802 - accuracy: 0.6821 - val_loss: 0.4888 - val_accuracy: 0.6643\n",
            "Epoch 27/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.4465 - accuracy: 0.7006 - val_loss: 0.4038 - val_accuracy: 0.7408\n",
            "Epoch 28/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.4267 - accuracy: 0.7094 - val_loss: 0.3805 - val_accuracy: 0.7741\n",
            "Epoch 29/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.4132 - accuracy: 0.7103 - val_loss: 0.3827 - val_accuracy: 0.7686\n",
            "Epoch 30/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 0.3868 - accuracy: 0.7293 - val_loss: 0.3462 - val_accuracy: 0.7808\n",
            "Epoch 31/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.3702 - accuracy: 0.7335 - val_loss: 0.3668 - val_accuracy: 0.7452\n",
            "Epoch 32/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.3488 - accuracy: 0.7472 - val_loss: 0.3475 - val_accuracy: 0.7926\n",
            "Epoch 33/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.3464 - accuracy: 0.7446 - val_loss: 0.3281 - val_accuracy: 0.7960\n",
            "Epoch 34/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.3260 - accuracy: 0.7586 - val_loss: 0.3218 - val_accuracy: 0.8019\n",
            "Epoch 35/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.3094 - accuracy: 0.7654 - val_loss: 0.3163 - val_accuracy: 0.7891\n",
            "Epoch 36/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.2976 - accuracy: 0.7666 - val_loss: 0.3029 - val_accuracy: 0.7876\n",
            "Epoch 37/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.2882 - accuracy: 0.7730 - val_loss: 0.2914 - val_accuracy: 0.8019\n",
            "Epoch 38/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2775 - accuracy: 0.7815 - val_loss: 0.2892 - val_accuracy: 0.8087\n",
            "Epoch 39/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2741 - accuracy: 0.7809 - val_loss: 0.2995 - val_accuracy: 0.7943\n",
            "Epoch 40/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.2547 - accuracy: 0.7943 - val_loss: 0.3139 - val_accuracy: 0.7965\n",
            "Epoch 41/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.2454 - accuracy: 0.8005 - val_loss: 0.2892 - val_accuracy: 0.8160\n",
            "Epoch 42/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2405 - accuracy: 0.8042 - val_loss: 0.2864 - val_accuracy: 0.8265\n",
            "Epoch 43/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2361 - accuracy: 0.8027 - val_loss: 0.2813 - val_accuracy: 0.8058\n",
            "Epoch 44/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2218 - accuracy: 0.8128 - val_loss: 0.2793 - val_accuracy: 0.8210\n",
            "Epoch 45/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2083 - accuracy: 0.8213 - val_loss: 0.2827 - val_accuracy: 0.8230\n",
            "Epoch 46/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.2186 - accuracy: 0.8152 - val_loss: 0.2780 - val_accuracy: 0.8104\n",
            "Epoch 47/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1899 - accuracy: 0.8357 - val_loss: 0.2841 - val_accuracy: 0.8302\n",
            "Epoch 48/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1877 - accuracy: 0.8402 - val_loss: 0.3205 - val_accuracy: 0.7819\n",
            "Epoch 49/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.2149 - accuracy: 0.8209 - val_loss: 0.2658 - val_accuracy: 0.8352\n",
            "Epoch 50/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1854 - accuracy: 0.8370 - val_loss: 0.2779 - val_accuracy: 0.8265\n",
            "Epoch 51/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1681 - accuracy: 0.8502 - val_loss: 0.2899 - val_accuracy: 0.8250\n",
            "Epoch 52/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.1730 - accuracy: 0.8451 - val_loss: 0.2714 - val_accuracy: 0.8328\n",
            "Epoch 53/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.1803 - accuracy: 0.8394 - val_loss: 0.2636 - val_accuracy: 0.8413\n",
            "Epoch 54/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1600 - accuracy: 0.8564 - val_loss: 0.2628 - val_accuracy: 0.8317\n",
            "Epoch 55/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1595 - accuracy: 0.8562 - val_loss: 0.2714 - val_accuracy: 0.8332\n",
            "Epoch 56/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.1487 - accuracy: 0.8653 - val_loss: 0.2683 - val_accuracy: 0.8341\n",
            "Epoch 57/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1500 - accuracy: 0.8625 - val_loss: 0.2929 - val_accuracy: 0.8374\n",
            "Epoch 58/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1394 - accuracy: 0.8699 - val_loss: 0.3879 - val_accuracy: 0.7191\n",
            "Epoch 59/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1366 - accuracy: 0.8719 - val_loss: 0.2989 - val_accuracy: 0.8404\n",
            "Epoch 60/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1426 - accuracy: 0.8679 - val_loss: 0.2834 - val_accuracy: 0.8406\n",
            "Epoch 61/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1277 - accuracy: 0.8786 - val_loss: 0.3022 - val_accuracy: 0.8361\n",
            "Epoch 62/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1346 - accuracy: 0.8747 - val_loss: 0.3084 - val_accuracy: 0.8239\n",
            "Epoch 63/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1443 - accuracy: 0.8662 - val_loss: 0.3309 - val_accuracy: 0.8182\n",
            "Epoch 64/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1229 - accuracy: 0.8815 - val_loss: 0.2850 - val_accuracy: 0.8434\n",
            "Epoch 65/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1128 - accuracy: 0.8926 - val_loss: 0.3108 - val_accuracy: 0.8393\n",
            "Epoch 66/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1217 - accuracy: 0.8791 - val_loss: 0.2803 - val_accuracy: 0.8513\n",
            "Epoch 67/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1162 - accuracy: 0.8861 - val_loss: 0.3387 - val_accuracy: 0.7965\n",
            "Epoch 68/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1254 - accuracy: 0.8778 - val_loss: 0.2915 - val_accuracy: 0.8469\n",
            "Epoch 69/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1097 - accuracy: 0.8905 - val_loss: 0.3255 - val_accuracy: 0.8254\n",
            "Epoch 70/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1058 - accuracy: 0.8945 - val_loss: 0.3074 - val_accuracy: 0.8437\n",
            "Epoch 71/100\n",
            "288/288 [==============================] - 18s 63ms/step - loss: 0.1153 - accuracy: 0.8843 - val_loss: 0.3741 - val_accuracy: 0.8002\n",
            "Epoch 72/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.1107 - accuracy: 0.8886 - val_loss: 0.2918 - val_accuracy: 0.8447\n",
            "Epoch 73/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1033 - accuracy: 0.8947 - val_loss: 0.3194 - val_accuracy: 0.8461\n",
            "Epoch 74/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0981 - accuracy: 0.9019 - val_loss: 0.3092 - val_accuracy: 0.8508\n",
            "Epoch 75/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1078 - accuracy: 0.8920 - val_loss: 0.3091 - val_accuracy: 0.8311\n",
            "Epoch 76/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1055 - accuracy: 0.8942 - val_loss: 0.2781 - val_accuracy: 0.8615\n",
            "Epoch 77/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0915 - accuracy: 0.9067 - val_loss: 0.3213 - val_accuracy: 0.8469\n",
            "Epoch 78/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0984 - accuracy: 0.8985 - val_loss: 0.3170 - val_accuracy: 0.8471\n",
            "Epoch 79/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1138 - accuracy: 0.8900 - val_loss: 0.3002 - val_accuracy: 0.8456\n",
            "Epoch 80/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.0827 - accuracy: 0.9147 - val_loss: 0.3189 - val_accuracy: 0.8495\n",
            "Epoch 81/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.0829 - accuracy: 0.9125 - val_loss: 0.3095 - val_accuracy: 0.8506\n",
            "Epoch 82/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0902 - accuracy: 0.9059 - val_loss: 0.3166 - val_accuracy: 0.8593\n",
            "Epoch 83/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.1000 - accuracy: 0.8989 - val_loss: 0.4125 - val_accuracy: 0.7699\n",
            "Epoch 84/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0900 - accuracy: 0.9047 - val_loss: 0.2994 - val_accuracy: 0.8626\n",
            "Epoch 85/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0845 - accuracy: 0.9105 - val_loss: 0.2894 - val_accuracy: 0.8669\n",
            "Epoch 86/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0730 - accuracy: 0.9222 - val_loss: 0.3327 - val_accuracy: 0.8517\n",
            "Epoch 87/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.1347 - accuracy: 0.8719 - val_loss: 0.3045 - val_accuracy: 0.8545\n",
            "Epoch 88/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0774 - accuracy: 0.9183 - val_loss: 0.3407 - val_accuracy: 0.8537\n",
            "Epoch 89/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.1004 - accuracy: 0.9001 - val_loss: 0.3533 - val_accuracy: 0.8091\n",
            "Epoch 90/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0776 - accuracy: 0.9182 - val_loss: 0.3700 - val_accuracy: 0.8269\n",
            "Epoch 91/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0922 - accuracy: 0.9014 - val_loss: 0.3480 - val_accuracy: 0.8454\n",
            "Epoch 92/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.0697 - accuracy: 0.9273 - val_loss: 0.3007 - val_accuracy: 0.8641\n",
            "Epoch 93/100\n",
            "288/288 [==============================] - 17s 61ms/step - loss: 0.0755 - accuracy: 0.9207 - val_loss: 0.2882 - val_accuracy: 0.8676\n",
            "Epoch 94/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0668 - accuracy: 0.9258 - val_loss: 0.4339 - val_accuracy: 0.7823\n",
            "Epoch 95/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0884 - accuracy: 0.9073 - val_loss: 0.3402 - val_accuracy: 0.8543\n",
            "Epoch 96/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0739 - accuracy: 0.9201 - val_loss: 0.3353 - val_accuracy: 0.8543\n",
            "Epoch 97/100\n",
            "288/288 [==============================] - 18s 61ms/step - loss: 0.0796 - accuracy: 0.9137 - val_loss: 0.3135 - val_accuracy: 0.8634\n",
            "Epoch 98/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0735 - accuracy: 0.9193 - val_loss: 0.3671 - val_accuracy: 0.8461\n",
            "Epoch 99/100\n",
            "288/288 [==============================] - 17s 60ms/step - loss: 0.0796 - accuracy: 0.9166 - val_loss: 0.3811 - val_accuracy: 0.8217\n",
            "Epoch 100/100\n",
            "288/288 [==============================] - 18s 62ms/step - loss: 0.0666 - accuracy: 0.9280 - val_loss: 0.3541 - val_accuracy: 0.8517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_test = model.predict(test_sequences)\n",
        "\n",
        "predicted_classes = np.argmax(predict_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9cBsJ6d2NW",
        "outputId": "7d6cf245-35a4-4bf5-9c41-94c92b847893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240/240 [==============================] - 5s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 예측 결과(predicted_labels)와 실제 레이블(true_labels) 비교\n",
        "accuracy = accuracy_score(labels_test, predicted_classes)\n",
        "\n",
        "f1_score = f1_score(labels_test, predicted_classes, average = 'weighted')\n",
        "\n",
        "\n",
        "print(f'accuracy : {accuracy:.3f}\\nF1-score : {f1_score:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfMq9XXTWkD4",
        "outputId": "ed91688c-d943-4075-c4cb-39db1c65c2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.841\n",
            "F1-score : 0.840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# 모델 저장하기\n",
        "model.save('./20230725_gru_best_up.h5')"
      ],
      "metadata": {
        "id": "UdaQw_jTK91c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context 벡터 뽑아내기"
      ],
      "metadata": {
        "id": "UeuMbsJfL7GO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZostFSWVJLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_up = data['cleand_up']\n",
        "raw_down = data['cleand_down']\n",
        "\n",
        "# corp dummiies\n",
        "corp_total = np.array(data.drop(['Unnamed: 0', 'corp', 'stock_code', 'cleand_up', 'cleand_down', 'year', 'sector', 'rank', 'label'], axis = 1))\n",
        "corp_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9p_OWmGUQj1",
        "outputId": "6403a963-e282-4e67-e541-14f25abc4a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/20230725_gru_best_up.h5')\n",
        "\n",
        "context_model = tf.keras.Model(inputs=model.input, outputs=model.layers[''].output)\n",
        "input_data = train_sequences\n",
        "\n",
        "context_vector = context_model.predict(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtMy74ULNkje",
        "outputId": "71f31a01-1819-466f-f44c-11d83f531b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3/575 [..............................] - ETA: 21s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "575/575 [==============================] - 20s 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1vVmyW0UQEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 재무데이터 합친 모델"
      ],
      "metadata": {
        "id": "k3_rU2LVUOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finalcial_df = pd.read_csv('/content/drive/MyDrive/final_a_df.csv', encoding = 'cp949')\n",
        "\n",
        "finalcial_df = finalcial_df[['corp', 'stock_code', 'year', 'rank',\n",
        "       'ebitda_margin', 'ebitda_to_interest_expense', 'debt_ratio',\n",
        "       'dependence_on_net_borrowings', 'net_borrowings_to_ebitda', 'revenue',\n",
        "       'cogs', 'selling_general_administrative_expenses', 'ebit',\n",
        "       'ebit_margin', 'ebitda_to_sales_revenue', 'total_assets',\n",
        "       'return_on_assets', 'ebitda', 'financial_expenses', 'corporate_tax',\n",
        "       'operating_cash_flow', 'free_cash_flow', 'total_liabilities',\n",
        "       'total_equity', 'total_borrowings', 'net_borrowings',\n",
        "       'borrowing_dependency', 'total_borrowings_to_ebitda',\n",
        "       'debt_to_net_income_ratio', 'total_assets_leverage',\n",
        "       'current_liabilities', 'working_capital', 'current_liabilities_ratio',\n",
        "       'quick_assets', 'quick_ratio', 'cash_and_cash_equivalents',\n",
        "       'short_term_borrowings', 'days_sales_outstanding',\n",
        "       'average_accounts_receivable_per_sales_turnover',\n",
        "       'market_capitalization', 'minimum_wage', 'us_kor_exchange_avg',\n",
        "       'ppi_year', 'kor_usa_ir_diff', 'kr_standard_yield', 'count', 'rating',\n",
        "       'paywellfare', 'worklifebal', 'culture', 'opportunity', 'manager',\n",
        "       'recommend', 'ceo', 'potential', 'crb_index_avg']]\n",
        "text_raw = data[['corp', 'stock_code', 'year', 'rank', 'label', 'cleand_up', 'cleand_down']]\n",
        "\n",
        "total_raw = text_raw.merge(finalcial_df, on = ['corp', 'stock_code', 'year', 'rank'], how = 'inner')"
      ],
      "metadata": {
        "id": "4IOAhFMtL6oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(data.drop(['Unnamed: 0', 'corp', 'stock_code', 'year', 'sector', 'rank'], axis = 1), test_size=0.25, stratify=data['label'].to_list())\n",
        "train_data, validation_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label'].to_list())"
      ],
      "metadata": {
        "id": "5bCgV-_6Mzpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corp dummiies\n",
        "corp_train = np.array(train_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))\n",
        "corp_valid = np.array(validation_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))\n",
        "corp_test = np.array(test_data.drop(['cleand_up', 'cleand_down', 'label'], axis = 1))"
      ],
      "metadata": {
        "id": "cwgkoUsUYuXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import SentencePieceBPETokenizer\n",
        "\n",
        "tokenizer = SentencePieceBPETokenizer()\n",
        "tokenizer.train('test_review.txt', vocab_size=5000, min_frequency=3)\n",
        "\n",
        "# train\n",
        "train_data['sp_up_train'] = train_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "train_data['sp_down_train'] = train_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "train_data['re_up_train'] = train_data['sp_up_train'].apply(lambda x: tokenizer.decode(x))\n",
        "train_data['re_down_train'] = train_data['sp_down_train'].apply(lambda x: tokenizer.decode(x))\n",
        "\n",
        "#valid\n",
        "validation_data['sp_up_valid'] = validation_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "validation_data['sp_down_valid'] = validation_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "validation_data['re_up_valid'] = validation_data['sp_up_valid'].apply(lambda x: tokenizer.decode(x))\n",
        "validation_data['re_down_valid'] = validation_data['sp_down_valid'].apply(lambda x: tokenizer.decode(x))\n",
        "\n",
        "# test\n",
        "test_data['sp_up_test'] = test_data['cleand_up'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "test_data['sp_down_test'] = test_data['cleand_down'].apply(lambda x: tokenizer.encode(x).ids)\n",
        "test_data['re_up_test'] = test_data['sp_up_test'].apply(lambda x: tokenizer.decode(x))\n",
        "test_data['re_down_test'] = test_data['sp_down_test'].apply(lambda x: tokenizer.decode(x))"
      ],
      "metadata": {
        "id": "SthS8A2MYuVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이즈\n",
        "tokenized_train = train_data['sp_down_train']\n",
        "tokenized_valid = validation_data['sp_down_valid']\n",
        "tokenized_test = test_data['sp_down_test']"
      ],
      "metadata": {
        "id": "8GMIxuMMYuS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 기술통계량\n",
        "train_cnt = pd.DataFrame([ len(tokenized_train.iloc[i]) for i in range(len(tokenized_train)) ], columns = ['train'])\n",
        "valid_cnt = pd.DataFrame([ len(tokenized_valid.iloc[i]) for i in range(len(tokenized_valid)) ], columns = ['valid'])\n",
        "test_cnt = pd.DataFrame([ len(tokenized_test.iloc[i]) for i in range(len(tokenized_test)) ], columns = ['test'])\n",
        "\n",
        "describe_1 = train_cnt.describe().values.tolist()\n",
        "describe_2 = valid_cnt.describe().values.tolist()\n",
        "describe_3 = test_cnt.describe().values.tolist()\n",
        "\n",
        "pd.DataFrame([describe_1, describe_2, describe_3], columns = train_cnt.describe().index)"
      ],
      "metadata": {
        "id": "kNPtmu6GYuQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "max_length = 50\n",
        "\n",
        "# train\n",
        "train_sequences = np.concatenate([pad_sequences(tokenized_train, maxlen=max_length, padding='post', truncating='post'), corp_train], axis = 1)\n",
        "labels_train = np.array(train_data['label'])\n",
        "\n",
        "# valid\n",
        "valid_sequences = np.concatenate([pad_sequences(tokenized_valid, maxlen=max_length, padding='post', truncating='post'), corp_valid], axis = 1)\n",
        "labels_valid = np.array(validation_data['label'])\n",
        "\n",
        "# test\n",
        "test_sequences = np.concatenate([pad_sequences(tokenized_test, maxlen=max_length, padding='post', truncating='post'), corp_test], axis = 1)\n",
        "labels_test = np.array(test_data['label'])"
      ],
      "metadata": {
        "id": "Mzds60cpYuOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, BatchNormalization\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define input layer\n",
        "input_layer1 = Input(shape=(max_length+len(data['corp'].unique()),))\n",
        "input_layer2 = Input(shape=(max_length+len(data['corp'].unique()),))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.get_vocab()), output_dim=512, input_length=max_length)(input_layer)\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.get_vocab()), output_dim=512, input_length=max_length)(input_layer)\n",
        "\n",
        "# LSTM layers\n",
        "gru_1 = GRU(256, activation='tanh', return_sequences=True)(embedding_layer)\n",
        "gru_2 = GRU(128, activation='tanh')(gru_1)\n",
        "\n",
        "# Dropout and BatchNormalization layers\n",
        "dropout_1 = Dropout(0.1)(gru_2)\n",
        "batchnorm_1 = BatchNormalization()(dropout_1)\n",
        "dense_1 = Dense(64, activation='relu')(batchnorm_1)\n",
        "\n",
        "dropout_2 = Dropout(0.1)(dense_1)\n",
        "batchnorm_2 = BatchNormalization()(dropout_2)\n",
        "dense_2 = Dense(32, activation='relu')(batchnorm_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(9, activation='softmax')(dense_2)\n",
        "\n",
        "# Create the functional model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Create an optimizer with a custom learning rate\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Focal Loss\n",
        "loss_func = SparseCategoricalFocalLoss(gamma=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Jb5-IItmYuL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_sequences,\n",
        "                    labels_train,\n",
        "                    validation_data=(valid_sequences, labels_valid),\n",
        "                    verbose= 1,\n",
        "                    epochs=100,\n",
        "                    batch_size=64)"
      ],
      "metadata": {
        "id": "LtjtWGlyYuJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_test = model.predict(test_sequences)\n",
        "\n",
        "predicted_classes = np.argmax(predict_test, axis=1)"
      ],
      "metadata": {
        "id": "ZLSd6fNDYuGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 예측 결과(predicted_labels)와 실제 레이블(true_labels) 비교\n",
        "accuracy = accuracy_score(labels_test, predicted_classes)\n",
        "\n",
        "f1_score = f1_score(labels_test, predicted_classes, average = 'weighted')\n",
        "\n",
        "\n",
        "print(f'accuracy : {accuracy:.3f}\\nF1-score : {f1_score:.3f}')"
      ],
      "metadata": {
        "id": "xxPBKjrpZHn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# 모델 저장하기\n",
        "model.save('./20230725_gru_best_up.h5')"
      ],
      "metadata": {
        "id": "P1Y3hoBbZHle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkAc9nNAZHjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWNf5j46ZHg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}